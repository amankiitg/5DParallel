{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amankiitg/5DParallel/blob/main/DataParallelization_GradientSynchronization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugUcoWgqnu28"
      },
      "source": [
        "# Data Parallelism: Gradient Synchronization Strategies\n",
        "\n",
        "## Naive DP (No Overlap) vs DDP (With Overlap)\n",
        "\n",
        "This notebook demonstrates the **key difference** between:\n",
        "\n",
        "1. **Naive DP** — All gradients are synchronized **AFTER** the entire backward pass completes (sequential: compute → communicate)\n",
        "2. **DDP with Overlap** — Gradients are synchronized **DURING** the backward pass as buckets become ready (overlapped: compute + communicate simultaneously)\n",
        "\n",
        "---\n",
        "\n",
        "### ⚠️ Critical Design Note\n",
        "\n",
        "A common mistake (and what the original code had) is implementing \"naive\" DP using `register_hook()` on parameters. **Hooks fire during backward** as each gradient is computed — which means all-reduce already overlaps with computation. That's essentially the same as DDP!\n",
        "\n",
        "**The fix:** For truly naive (no-overlap) DP, we must:\n",
        "- Do `loss.backward()` with **no hooks** and **no DDP wrapper**\n",
        "- **After** backward completes, manually loop over all parameters and call `all_reduce` on each gradient\n",
        "\n",
        "This ensures communication is fully sequential after computation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1ZzmSsUnu2-"
      },
      "source": [
        "## Step 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssEmhCS9nu2-"
      },
      "outputs": [],
      "source": [
        "# Uncomment and run once if needed\n",
        "# !pip install torch torchvision tensorboard torch-tb-profiler -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO6_se9Dnu2_"
      },
      "source": [
        "## Step 2: Create the Naive DP Script (NO Overlap)\n",
        "\n",
        "**Key idea:** We wrap the model in a simple `nn.Module` with **NO hooks**. After `loss.backward()` finishes completely, we manually call `dist.all_reduce()` on every gradient in a separate loop. This creates a clear **sequential** pattern:\n",
        "\n",
        "```\n",
        "backward (all compute) ──────────────> | all_reduce (all communication) ──────────────>\n",
        "```\n",
        "\n",
        "We also use a **deeper and wider model** (40 layers × 4096 width) so the backward pass is long enough to clearly see the separation in the trace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c_kuIHJnu3A"
      },
      "outputs": [],
      "source": [
        "naive_dp_code = '''\n",
        "import os, argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.distributed as dist\n",
        "from torch.profiler import profile, ProfilerActivity, record_function\n",
        "\n",
        "\n",
        "def build_model(depth=40, width=4096):\n",
        "    \"\"\"Build a deep MLP to make backward pass long enough to see overlap differences.\n",
        "\n",
        "    Using 40 layers x 4096 width gives us:\n",
        "    - A long backward pass with many sequential gradient computations\n",
        "    - Large gradients (4096x4096 = 16M params per layer) that make all_reduce visible\n",
        "    \"\"\"\n",
        "    layers = []\n",
        "    for _ in range(depth):\n",
        "        layers += [nn.Linear(width, width, bias=False), nn.ReLU()]\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def main():\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"--logdir\", type=str, required=True)\n",
        "    p.add_argument(\"--steps\", type=int, default=10)\n",
        "    p.add_argument(\"--batch\", type=int, default=64)\n",
        "    args = p.parse_args()\n",
        "\n",
        "    # Initialize distributed training\n",
        "    local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
        "    rank = int(os.environ[\"RANK\"])\n",
        "    world_size = int(os.environ[\"WORLD_SIZE\"])\n",
        "\n",
        "    torch.cuda.set_device(local_rank)\n",
        "    dist.init_process_group(backend=\"nccl\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # NAIVE DP: Plain model with NO hooks, NO DDP wrapper\n",
        "    # We will manually all-reduce gradients AFTER backward completes\n",
        "    # =========================================================================\n",
        "    model = build_model().cuda()\n",
        "    opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "    # Broadcast initial parameters so all ranks start with the same weights\n",
        "    for p_tensor in model.parameters():\n",
        "        dist.broadcast(p_tensor.data, src=0)\n",
        "\n",
        "    # Synthetic data\n",
        "    x = torch.randn(args.batch, 4096, device=\"cuda\")\n",
        "    target = torch.randn(args.batch, 4096, device=\"cuda\")\n",
        "\n",
        "    # Warmup (3 steps to stabilize CUDA kernels and NCCL)\n",
        "    for _ in range(3):\n",
        "        y = model(x)\n",
        "        loss = (y - target).pow(2).mean()\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        # Manual all-reduce after backward\n",
        "        for p_tensor in model.parameters():\n",
        "            if p_tensor.grad is not None:\n",
        "                dist.all_reduce(p_tensor.grad, op=dist.ReduceOp.SUM)\n",
        "                p_tensor.grad /= world_size\n",
        "        opt.step()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "    # Profile\n",
        "    worker_name = f\"rank{rank}\"\n",
        "    prof_schedule = torch.profiler.schedule(wait=2, warmup=1, active=3, repeat=1)\n",
        "\n",
        "    with profile(\n",
        "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "        schedule=prof_schedule,\n",
        "        on_trace_ready=torch.profiler.tensorboard_trace_handler(\n",
        "            args.logdir, worker_name=worker_name\n",
        "        ),\n",
        "        record_shapes=True,\n",
        "        profile_memory=True,\n",
        "        with_stack=False,\n",
        "    ) as prof:\n",
        "        for step in range(args.steps):\n",
        "            dist.barrier()\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "            with record_function(f\"step_{step}\"):\n",
        "\n",
        "                with record_function(\"forward\"):\n",
        "                    y = model(x)\n",
        "\n",
        "                with record_function(\"loss\"):\n",
        "                    loss = (y - target).pow(2).mean()\n",
        "\n",
        "                opt.zero_grad()\n",
        "\n",
        "                # ---------------------------------------------------------\n",
        "                # NAIVE BACKWARD: Pure computation, NO communication here\n",
        "                # ---------------------------------------------------------\n",
        "                with record_function(\"backward_COMPUTE_ONLY\"):\n",
        "                    loss.backward()\n",
        "\n",
        "                # Force backward to fully complete on GPU before communication\n",
        "                torch.cuda.synchronize()\n",
        "\n",
        "                # ---------------------------------------------------------\n",
        "                # NAIVE ALL-REDUCE: ALL communication happens here, AFTER\n",
        "                # backward is 100% done. This is the \"no overlap\" part.\n",
        "                # ---------------------------------------------------------\n",
        "                with record_function(\"allreduce_ALL_GRADS_SEQUENTIAL\"):\n",
        "                    for p_tensor in model.parameters():\n",
        "                        if p_tensor.grad is not None:\n",
        "                            dist.all_reduce(p_tensor.grad, op=dist.ReduceOp.SUM)\n",
        "                            p_tensor.grad /= world_size\n",
        "\n",
        "                torch.cuda.synchronize()\n",
        "\n",
        "                with record_function(\"optimizer\"):\n",
        "                    opt.step()\n",
        "\n",
        "                torch.cuda.synchronize()\n",
        "\n",
        "            prof.step()\n",
        "\n",
        "    dist.destroy_process_group()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "\n",
        "with open(\"naive_dp_profile.py\", \"w\") as f:\n",
        "    f.write(naive_dp_code)\n",
        "\n",
        "print(\"✓ Created naive_dp_profile.py\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI6wL9Eonu3B"
      },
      "source": [
        "## Step 3: Create the DDP Script (WITH Overlap)\n",
        "\n",
        "**Key idea:** PyTorch's `DistributedDataParallel` (DDP) groups parameters into **buckets** and fires `all_reduce` on each bucket as soon as all gradients in that bucket are ready — while backward is still running for earlier layers. This creates an **overlapped** pattern:\n",
        "\n",
        "```\n",
        "backward: [layer40 grad]──[layer39 grad]──[layer38 grad]──[layer37 grad]──...\n",
        "comms:                     [allreduce bucket1]──────────[allreduce bucket2]──────...\n",
        "```\n",
        "\n",
        "We use a **small bucket size** (`bucket_cap_mb=5`) to create more frequent, smaller all-reduce calls — making the overlap more visible in the trace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCx6QMBwnu3B"
      },
      "outputs": [],
      "source": [
        "ddp_overlap_code = '''\n",
        "import os, argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.distributed as dist\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "from torch.profiler import profile, ProfilerActivity, record_function\n",
        "\n",
        "\n",
        "def build_model(depth=40, width=4096):\n",
        "    \"\"\"Same model architecture as naive DP for fair comparison.\"\"\"\n",
        "    layers = []\n",
        "    for _ in range(depth):\n",
        "        layers += [nn.Linear(width, width, bias=False), nn.ReLU()]\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def main():\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"--logdir\", type=str, required=True)\n",
        "    p.add_argument(\"--steps\", type=int, default=10)\n",
        "    p.add_argument(\"--batch\", type=int, default=64)\n",
        "    p.add_argument(\"--bucket_cap_mb\", type=int, default=5)\n",
        "    args = p.parse_args()\n",
        "\n",
        "    # Initialize distributed training\n",
        "    local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
        "    rank = int(os.environ[\"RANK\"])\n",
        "    world_size = int(os.environ[\"WORLD_SIZE\"])\n",
        "\n",
        "    torch.cuda.set_device(local_rank)\n",
        "    dist.init_process_group(backend=\"nccl\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # DDP: Wraps model with automatic gradient bucketing + overlapped all-reduce\n",
        "    # - bucket_cap_mb=5: Small buckets → more frequent all-reduce calls\n",
        "    #   (makes overlap pattern more visible in profiler trace)\n",
        "    # - gradient_as_bucket_view=True: Avoid extra gradient copy\n",
        "    # =========================================================================\n",
        "    model = build_model().cuda()\n",
        "    ddp = DDP(\n",
        "        model,\n",
        "        device_ids=[local_rank],\n",
        "        broadcast_buffers=False,\n",
        "        bucket_cap_mb=args.bucket_cap_mb,\n",
        "        gradient_as_bucket_view=True,\n",
        "    )\n",
        "    opt = torch.optim.SGD(ddp.parameters(), lr=0.01)\n",
        "\n",
        "    # Synthetic data\n",
        "    x = torch.randn(args.batch, 4096, device=\"cuda\")\n",
        "    target = torch.randn(args.batch, 4096, device=\"cuda\")\n",
        "\n",
        "    # Warmup\n",
        "    for _ in range(3):\n",
        "        y = ddp(x)\n",
        "        loss = (y - target).pow(2).mean()\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "    # Profile\n",
        "    worker_name = f\"rank{rank}\"\n",
        "    prof_schedule = torch.profiler.schedule(wait=2, warmup=1, active=3, repeat=1)\n",
        "\n",
        "    with profile(\n",
        "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "        schedule=prof_schedule,\n",
        "        on_trace_ready=torch.profiler.tensorboard_trace_handler(\n",
        "            args.logdir, worker_name=worker_name\n",
        "        ),\n",
        "        record_shapes=True,\n",
        "        profile_memory=True,\n",
        "        with_stack=False,\n",
        "    ) as prof:\n",
        "        for step in range(args.steps):\n",
        "            dist.barrier()\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "            with record_function(f\"step_{step}\"):\n",
        "\n",
        "                with record_function(\"forward\"):\n",
        "                    y = ddp(x)\n",
        "\n",
        "                with record_function(\"loss\"):\n",
        "                    loss = (y - target).pow(2).mean()\n",
        "\n",
        "                opt.zero_grad()\n",
        "\n",
        "                # ---------------------------------------------------------\n",
        "                # DDP BACKWARD: Computation and communication are OVERLAPPED\n",
        "                # As each bucket of gradients is computed, DDP automatically\n",
        "                # fires all_reduce on that bucket while backward continues\n",
        "                # computing gradients for earlier layers.\n",
        "                # ---------------------------------------------------------\n",
        "                with record_function(\"backward_WITH_OVERLAP\"):\n",
        "                    loss.backward()\n",
        "\n",
        "                torch.cuda.synchronize()\n",
        "\n",
        "                with record_function(\"optimizer\"):\n",
        "                    opt.step()\n",
        "\n",
        "                torch.cuda.synchronize()\n",
        "\n",
        "            prof.step()\n",
        "\n",
        "    dist.destroy_process_group()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "\n",
        "with open(\"ddp_overlap_profile.py\", \"w\") as f:\n",
        "    f.write(ddp_overlap_code)\n",
        "\n",
        "print(\"✓ Created ddp_overlap_profile.py\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49e78gaQnu3C"
      },
      "source": [
        "## Step 4: Run Experiment 1 — Naive DP (No Overlap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiswMh46nu3C"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import time\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"EXPERIMENT 1: Naive Data Parallelism (NO overlap)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Clean old logs\n",
        "subprocess.run(\"rm -rf logs/naive_dp\", shell=True)\n",
        "\n",
        "# Run naive DP\n",
        "result = subprocess.run(\n",
        "    \"torchrun --standalone --nproc_per_node=2 naive_dp_profile.py \"\n",
        "    \"--logdir logs/naive_dp --steps 10 --batch 64\",\n",
        "    shell=True,\n",
        "    capture_output=True,\n",
        "    text=True,\n",
        ")\n",
        "print(result.stdout)\n",
        "if result.returncode != 0:\n",
        "    print(\"STDERR:\", result.stderr[-2000:])  # Last 2000 chars of error\n",
        "else:\n",
        "    print(\"✓ Naive DP profiling complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3Khgy5Cnu3D"
      },
      "source": [
        "## Step 5: Run Experiment 2 — DDP with Overlap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NML9dlBunu3D"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"EXPERIMENT 2: DDP with Communication Overlap\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "time.sleep(2)\n",
        "\n",
        "# Clean old logs\n",
        "subprocess.run(\"rm -rf logs/ddp_overlap\", shell=True)\n",
        "\n",
        "# Run DDP with overlap (small bucket size to maximize visible overlap)\n",
        "result = subprocess.run(\n",
        "    \"torchrun --standalone --nproc_per_node=2 ddp_overlap_profile.py \"\n",
        "    \"--logdir logs/ddp_overlap --steps 10 --batch 64 --bucket_cap_mb 5\",\n",
        "    shell=True,\n",
        "    capture_output=True,\n",
        "    text=True,\n",
        ")\n",
        "print(result.stdout)\n",
        "if result.returncode != 0:\n",
        "    print(\"STDERR:\", result.stderr[-2000:])\n",
        "else:\n",
        "    print(\"✓ DDP overlap profiling complete!\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"✓ Both experiments completed!\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nGenerated trace logs:\")\n",
        "print(\"  - logs/naive_dp/      (NO overlap)\")\n",
        "print(\"  - logs/ddp_overlap/   (WITH overlap)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8teIJcW0nu3E"
      },
      "source": [
        "## Step 6: View Results in TensorBoard\n",
        "\n",
        "### Launch TensorBoard\n",
        "\n",
        "```bash\n",
        "# In a terminal on RunPod:\n",
        "cd /workspace\n",
        "pkill -f tensorboard\n",
        "tensorboard --logdir logs --host 0.0.0.0 --port 6007\n",
        "```\n",
        "\n",
        "Then SSH tunnel from your local machine:\n",
        "```bash\n",
        "ssh root@<RUNPOD_IP> -p <PORT> -i ~/.ssh/id_ed25519 -L 6007:localhost:6007\n",
        "```\n",
        "\n",
        "Open `http://localhost:6007` → **PYTORCH_PROFILER** tab → **Trace** view.\n",
        "\n",
        "---\n",
        "\n",
        "### What to Look For in the Trace View\n",
        "\n",
        "#### Naive DP (No Overlap) — `naive_dp`\n",
        "\n",
        "You should see **two distinct, sequential blocks**:\n",
        "\n",
        "```\n",
        "CPU:  |── backward_COMPUTE_ONLY ──|── allreduce_ALL_GRADS_SEQUENTIAL ──|\n",
        "GPU:  |███ compute kernels ███████|░░░░░░░░ idle ░░░░░░░░░░░░░░░░░░░░░░|\n",
        "NCCL: |░░░░░░░░ idle ░░░░░░░░░░░░|███ nccl:all_reduce ████████████████|\n",
        "```\n",
        "\n",
        "- `backward_COMPUTE_ONLY` region: only compute kernels (matmul, ReLU backward), **zero NCCL calls**\n",
        "- `allreduce_ALL_GRADS_SEQUENTIAL` region: a **burst of nccl:all_reduce** calls, one per parameter, all bunched together\n",
        "- The GPU compute stream is **idle** during the all-reduce phase\n",
        "\n",
        "#### DDP with Overlap — `ddp_overlap`\n",
        "\n",
        "You should see **interleaved compute and communication**:\n",
        "\n",
        "```\n",
        "CPU:  |──────────── backward_WITH_OVERLAP ──────────────|\n",
        "GPU:  |███ compute ██ compute ██ compute ██ compute ████|\n",
        "NCCL: |░░░░░░░░░███ allreduce ████ allreduce ████ allreduce █████|\n",
        "```\n",
        "\n",
        "- Inside `backward_WITH_OVERLAP`: you see both compute kernels AND `nccl:all_reduce` calls **happening simultaneously**\n",
        "- `c10d::allreduce_` and `record_param_comms` operations appear **interleaved** with backward compute\n",
        "- The NCCL stream shows all-reduce calls **overlapping** with the GPU compute stream\n",
        "- Overall step time should be **shorter** since communication is hidden behind computation"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}